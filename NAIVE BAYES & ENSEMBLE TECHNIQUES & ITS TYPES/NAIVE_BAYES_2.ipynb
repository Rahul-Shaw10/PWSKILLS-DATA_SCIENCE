{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "### [Q1.] A company conducted a survey of its employees and found that 70% of the employees use the company's health insurance plan, while 40% of the employees who use the plan are smokers. What is the probability that an employee is a smoker given that he/she uses the health insurance plan?\n",
        "##### [Ans]\n",
        "\n",
        "Given :\n",
        "Probabilty of employees use company insurance is :\n",
        "$$\n",
        "P(Insurance) = 0.7\n",
        "$$\n",
        "Probability of employees use company insurance but smoke is :\n",
        "$$\n",
        "P(Smokers|Insurance) = 0.4\n",
        "$$\n",
        "So, basically the answer is in the question so the answer is 0.4"
      ],
      "metadata": {
        "id": "WpjG_CtNtCau"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "###[Q2.] What is the difference between Bernoulli Naive Bayes and Multinomial Naive Bayes?\\\n",
        "#####[Ans]\n",
        "\n",
        "| Aspect | Bernoulli Naive Bayes | Multinomial Naive Bayes |\n",
        "| ------ | --------------------- | ----------------------- |\n",
        "| Data Type |\tWorks with binary data (0 or 1). | Works with count-based data (integer or frequency). |\n",
        "| Feature Assumption |Assumes features are either present (1) or absent (0). |\tAssumes features represent counts or frequencies. |\n",
        "| Use Case | Binary classification problems, such as spam detection where features indicate presence/absence of words. | Text classification with word counts, such as topic modeling or sentiment analysis. |"
      ],
      "metadata": {
        "id": "fz0M8Zl5t8tp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "###[Q3.] How does Bernoulli Naive Bayes handle missing values?\n",
        "#####[Ans]\n",
        "\n",
        "Bernoulli Naive Bayes does not inherently handle missing values. However, common strategies include:\n",
        "\n",
        "- Imputation: Replacing missing values with the most common value (mode) or based on domain knowledge.\n",
        "- Data Preparation: Dropping rows or columns with missing values before applying the classifier."
      ],
      "metadata": {
        "id": "ekdtAY25uctu"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "###[Q4.] Can Gaussian Naive Bayes be used for multi-class classification?\n",
        "#####[Ans]\n",
        "\n",
        "Yes, Gaussian Naive Bayes can be used for multi-class classification. Scikit-learn's implementation handles multiple classes using the one-vs-rest strategy, where a separate binary model is trained for each class. The model predicts the class with the highest posterior probability."
      ],
      "metadata": {
        "id": "9bbIfMUfunKD"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "###[Q5.] Assignment:\n",
        "- **Data preparation:**\n",
        "\n",
        "Download the \"Spambase Data Set\" from the UCI Machine Learning Repository (https://archive.ics.uci.edu/ml/datasets/Spambase). This dataset contains email messages, where the goal is to predict whether a message is spam or not based on several input features.<br>\n",
        "- **Implementation:**\n",
        "\n",
        "Implement Bernoulli Naive Bayes, Multinomial Naive Bayes, and Gaussian Naive Bayes classifiers using the\n",
        "scikit-learn library in Python. Use 10-fold cross-validation to evaluate the performance of each classifier on the\n",
        "dataset. You should use the default hyperparameters for each classifier.<br>\n",
        "- **Results:**\n",
        "\n",
        "Report the following performance metrics for each classifier:<br>\n",
        "1. Accuracy<br>\n",
        "2. Precision<br>\n",
        "3. Recall<br>\n",
        "4. F1 score<br>\n",
        "- **Discussion:**\n",
        "\n",
        "Discuss the results you obtained. Which variant of Naive Bayes performed the best? Why do you think that is\n",
        "the case? Are there any limitations of Naive Bayes that you observed?\n",
        "- **Conclusion:**\n",
        "\n",
        "Summarise your findings and provide some suggestions for future work."
      ],
      "metadata": {
        "id": "mo2yEZ8EuzWU"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0uAn7296s-Vh",
        "outputId": "26d2175c-9e90-475a-ce83-e8d3c81de9d9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "BernoulliNB Performance :\n",
            "Accuracy : 0.8791\n",
            "Precision : 0.8883\n",
            "Recall : 0.8128\n",
            "F1 Score : 0.8489\n",
            "\n",
            "MultinomialNB Performance :\n",
            "Accuracy : 0.7820\n",
            "Precision : 0.7624\n",
            "Recall : 0.6950\n",
            "F1 Score : 0.7271\n",
            "\n",
            "GaussianNB Performance :\n",
            "Accuracy : 0.8248\n",
            "Precision : 0.7207\n",
            "Recall : 0.9480\n",
            "F1 Score : 0.8189\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split, cross_val_score, cross_validate\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
        "from sklearn.naive_bayes import BernoulliNB, MultinomialNB, GaussianNB\n",
        "\n",
        "data = pd.read_csv(\"spambase.data\", header=None)\n",
        "X = data.iloc[:, :-1]\n",
        "y = data.iloc[:, -1]\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.3, random_state=42)\n",
        "\n",
        "classifiers = {\n",
        "    \"BernoulliNB\" : BernoulliNB(),\n",
        "    \"MultinomialNB\" : MultinomialNB(),\n",
        "    \"GaussianNB\" : GaussianNB()\n",
        "}\n",
        "\n",
        "results = {}\n",
        "for name, clf in classifiers.items():\n",
        "  clf.fit(X_train, y_train)\n",
        "  y_pred = clf.predict(X_test)\n",
        "  results[name] = {\n",
        "      \"Accuracy\" : accuracy_score(y_test, y_pred),\n",
        "      \"Precision\" : precision_score(y_test, y_pred),\n",
        "      \"Recall\" : recall_score(y_test, y_pred),\n",
        "      \"F1 Score\" : f1_score(y_test, y_pred)\n",
        "  }\n",
        "\n",
        "for name, metrics in results.items():\n",
        "  print(f\"\\n{name} Performance :\")\n",
        "  for metric, value in metrics.items():\n",
        "    print(f\"{metric} : {value:.4f}\")"
      ]
    }
  ]
}