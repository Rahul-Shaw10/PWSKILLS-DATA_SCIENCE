{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "###[Q1.] What is an ensemble technique in machine learning?\n",
        "#####[Ans]\n",
        "An ensemble technique in machine learning combines the predictions of multiple individual models to produce a more robust and accurate final model. The goal is to leverage the strengths of each model while minimizing their weaknesses."
      ],
      "metadata": {
        "id": "PLdplcOHrB4Z"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "###[Q2.] Why are ensemble techniques used in machine learning?\n",
        "#####[Ans]\n",
        "Ensemble techniques are used because they:\n",
        "\n",
        "1. Improve prediction accuracy.\n",
        "2. Reduce the risk of overfitting.\n",
        "3. Enhance model robustness by combining diverse models.\n",
        "4. Help in handling complex datasets where individual models may fail."
      ],
      "metadata": {
        "id": "6r203HXPrL9P"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "###[Q3.] What is bagging?\n",
        "#####[Ans]\n",
        "Bagging (Bootstrap Aggregating) is an ensemble technique where:\n",
        "\n",
        "1. Multiple models are trained on different bootstrapped (randomly sampled with replacement) subsets of the data.\n",
        "2. The predictions of these models are aggregated (e.g., averaged for regression, majority voting for classification).\n",
        "\n",
        "Example: Random Forest uses bagging with decision trees."
      ],
      "metadata": {
        "id": "OSmFM-J-rL6Z"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "###[Q4.] What is boosting?\n",
        "#####[Ans]\n",
        "Boosting is an ensemble technique that:\n",
        "\n",
        "- Trains models sequentially, where each model tries to correct the errors of its predecessor.\n",
        "- Assigns higher weights to misclassified samples in subsequent models.\n",
        "- Combines the predictions of all models, often using weighted sums.\n",
        "\n",
        "Example: Gradient Boosting, AdaBoost."
      ],
      "metadata": {
        "id": "frIVANuVrL37"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "###[Q5.] What are the benefits of using ensemble techniques?\n",
        "#####[Ans]\n",
        "- Improved accuracy: Combining multiple models often yields better performance than individual models.\n",
        "- Reduced variance: Helps prevent overfitting.\n",
        "- Robustness: Handles noisy data better.\n",
        "- Adaptability: Effective for both classification and regression tasks."
      ],
      "metadata": {
        "id": "bzf77WX4rL1X"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "###[Q6.] Are ensemble techniques always better than individual models?\n",
        "#####[Ans]\n",
        "Not always. Ensemble techniques:\n",
        "\n",
        "- May not improve performance if the individual models are already optimal.\n",
        "- Can increase computational cost and complexity.\n",
        "- Require careful tuning to avoid overfitting or underfitting.\n"
      ],
      "metadata": {
        "id": "614k-HQdrLzA"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "###[Q7.] How is the confidence interval calculated using bootstrap?\n",
        "#####[Ans]\n",
        "Using bootstrap, the confidence interval is estimated by:\n",
        "\n",
        "- Generating multiple bootstrap samples from the data.\n",
        "- Calculating the statistic (e.g., mean) for each sample.\n",
        "- Computing the percentiles (e.g., 2.5% and 97.5% for a 95% confidence interval) of the bootstrap statistics."
      ],
      "metadata": {
        "id": "DIab85fXrLwm"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "###[Q8.] How does bootstrap work and What are the steps involved in bootstrap?\n",
        "#####[Ans]\n",
        "Bootstrap is a resampling technique to estimate the sampling distribution of a statistic.\n",
        "\n",
        "Steps:\n",
        "\n",
        "- Randomly sample the data with replacement to create a bootstrap sample.\n",
        "- Compute the desired statistic (e.g., mean, variance) for the sample.\n",
        "- Repeat steps 1â€“2 multiple times to build a distribution of the statistic.\n",
        "- Use the bootstrap distribution to estimate parameters, confidence intervals, or other metrics."
      ],
      "metadata": {
        "id": "Ktg_ESGmrLKp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "###[Q9.] A researcher wants to estimate the mean height of a population of trees. They measure the height of a sample of 50 trees and obtain a mean height of 15 meters and a standard deviation of 2 meters. Use bootstrap to estimate the 95% confidence interval for the population mean height.\n",
        "#####[Ans]"
      ],
      "metadata": {
        "id": "3iGupe6NtWDj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "sample_size = 50\n",
        "sample_mean = 15\n",
        "sample_std = 2\n",
        "\n",
        "np.random.seed(42)\n",
        "original_sample = np.random.normal(loc=sample_mean, scale=sample_std, size=sample_size)\n",
        "\n",
        "num_bootstrap_samples = 10000\n",
        "bootstrap_means = []\n",
        "\n",
        "for _ in range(num_bootstrap_samples):\n",
        "    bootstrap_sample = np.random.choice(original_sample, size=sample_size, replace=True)\n",
        "    bootstrap_means.append(np.mean(bootstrap_sample))\n",
        "\n",
        "lower_bound = np.percentile(bootstrap_means, 2.5)\n",
        "upper_bound = np.percentile(bootstrap_means, 97.5)\n",
        "\n",
        "print(f\"95% Confidence Interval for Population Mean Height: ({lower_bound:.2f}, {upper_bound:.2f})\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ndmj8M77rKKM",
        "outputId": "b754e7de-838c-49fa-b8c8-b41c062b3550"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "95% Confidence Interval for Population Mean Height: (14.03, 15.06)\n"
          ]
        }
      ]
    }
  ]
}